\chapter{Conclusion and Perspectives}
Seismic modelling is computationally expensive, and use high performance computing to produce timely results. There are many factors that could affect performance such as functional unit utilization, load balance between nodes, contention for resources such as interconnect and memory bandwidth, synchronization delays, memory hierarchy and pipeline utilization. The aim of this work was to evaluate the capacity of DSFDM/FFWI to extend high tests case on a modern share node, MESCA-II. Moreover, we will improve the performance of the code in this architecture. To do this job, we focused on three things: firstly, installation and getting started with DSFDM/FFWI code in a distributed cluster containing the MESCA-II node; studying its performance based on strong and weak scalability, understanding and optimisation of code by using profiling tools. In this study, we have done a deep analysis of performance in two difference architectures. We have found that perfect strong scalability of DSFDM/FFWI on Mesca node. We got the limit of scalability in MESCA-II where the size equals to $260^3$ with 3TB with 1h 20mn. However, the weak scalability that we studied in both architectures does not give any relevant results when we want to extend the problem size. 
With the profiling tools we discovered, most of the resources was consumed by the mumps routines and the time spent in these routines make up almost 90\% of the total execution time. In the future work, the case of Block-Low Rank (BLR) of  MUMPS will be  tested with difference case of study. In perspective, to improve the performance of DSFDM/FFWI and to extend tests case in non-scare matrices, we implemented a new solver interface depending 
on \verb|QR_MUMPS| (a new solver based on QR factorization). Given some constraints based on the extensibility of the code for the new solver, we have not yet obtained the expected results. 
 